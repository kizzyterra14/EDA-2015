\documentclass{article}
\usepackage{amssymb,amsmath}
\usepackage[procnames]{listings}
\usepackage{color}

\begin{document}
  \definecolor{keywords}{RGB}{255,0,90}
  \definecolor{comments}{RGB}{0,0,113}
  \definecolor{red}{RGB}{160,0,0}
  \definecolor{green}{RGB}{0,150,0}
   \lstset{language=Python,
          basicstyle=\ttfamily\small,
          keywordstyle=\color{keywords},
          commentstyle=\color{comments},
          stringstyle=\color{red},
          showstringspaces=false,
          identifierstyle=\color{green},
          procnamekeys={def,class}}

\title{Exercicio Selecionado 4}


\section{Enunciado}

O Exerc\'{\i}cio a seguir foi extra\'{\i}do do livro Algorithm Design de John Kleinberg e de Eva Tardos,
capitulo 4, sendo o exerc\'{\i}cio de numero 7. Vamos exp\^or apenas um resumo do enunciado, com as principais
informa\c{c}\~oes para resolu\c{c}\~ao de tal exerc\'{\i}cio. Destaca-se aqui, que a escolha desse exerc\'{\i}cio foi
pautada pelo interesse em enunciar e provar a efici\^encia de um algoritmo guloso.

Dado um problema, um algoritmo guloso tem como principal caracter\'{\i}stica construir uma solu\c{c}\~ao
em pequenos passos, de modo a escolher uma a\c{c}\~ao a cada passo sob um determinado crit\'erio, com o
objetivo de otimizar a solu\c{c}\~ao final. Dessa forma, ao final da rotina, deve-se retornar como sa\'{\i}da uma solu\c{c}\~ao \'otima.
\'E poss\'{\i}vel identificar diferentes crit\'erios para resolu\c{c}\~ao de um problema, por interm\'edio de um algoritmo guloso, por\'em,
n\~ao necessariamente, o crit\'erio escolhido nos leva \`a solu\c{c}\~ao \'otima. Dessa forma, ap\'os construir um algoritmo guloso,
se faz necess\'ario provar que a solu\c{c}\~ao proposta por tal algoritmo \'e \'otima, sendo esse o nosso objetivo com esse exerc\'{\i}cio.

O supercomputador exerce trabalhos diferentes que possuem tempo final P1, P2,...,Pn.
Um trabalho exercido pelo supercomputador Pi s\'o se inicia quando outro Pi-1 termina.
Ap\'os o trabalho do supercomputador, \'e necess\'ario o trabalho de um PC para processamento
dos dados. Os PCs possuem tempo final de trabalho da ordem de f1,f2,...,fn. Pergunta-se: Qual
a melhor forma de alocar os trabalhos dos supercomputadores e dos PCs de modo a minimizar o
tempo de processamento do dado.

\section{Prova de Otimalidade}
A primeira etapa ser\'a analisar os jobs do supercomputador. Como ja dito no enunciado, Pi
ser\'a o valor da dura\c{c}\~ao dos jobs do supercomputador e Fi o valor dura\c{c}\~ao dos jobs dos PCs.

    Uma vez que todos os jobs de um PC iniciam necessariamente ap\'os o job de um supercomputador, e como os
    jobs dos supercomputadores devem ser ordenados de modo que nao haja sobreposi\c{c}\~ao entre seus valores,
    podemos inferir que a ordem dos supercomputadores \'e indiferente, pois dadas as hipoteses listadas, o
    que de fato ir\'a interferir no tempo final dos jobs ser\'a a ordem dos trabalhos dos PCs.

    Com efeito, nosso algoritmo A exposto em c\'odigo python na pr\`oxima se\c{c}\~ao ordena a dura\c{c}\~ao
    dos jobs feitos pelos PCs em ordem decrescente. Em resumo, nosso crit\`erio ser\'a escolher a cada passo
    o job de um PC de maior valor. Atrav\'es desse algoritmo, vamos ser capazes de alocar os jobs dos supercomputadores
    e dos PCs de modo a gastar o menor tempo poss\'i{\i}vel nessa tarefa, como ser\'a provado a seguir:

\it Passo Base: Seja k a itera\c{c}\~ao no tempo, temos nesse passo k = 1.

Seja Fi* o job de maior dura\c{c}\~ao feito por um PC, sup\~oe-se um algoritmo O que n\~ao posiciona o job Fi*
na primeira posi\c{c}\~ao, isto \'e, ap\'os o termino do job do primeiro supercomputador. Isso nos leva \`a
conclus\~ao de que o algoritmo O n\~ao ordena os trabalhos dos PCs em ordem decrescente dos valores de
dura\c{c}\~ao. Aqui, destaca-se o fato de que para um job de um PC come\c{c}ar o de um supercomputador deve
terminar e, no passo base, apenas um job P1 foi conclu\'{\i}do por um supercomputador. Seja T o tempo gasto
pelo algoritmo A implementado nesse artigo e seja T` o tempo gasto pelo algoritmo O, pode-se afirmar que:

\begin{equation}\label{Inducao}
  \begin{split}
    T = P1 + Fi* < P-1 + Fi* = T`
      \end{split}
\end{equation}

Ao considerar P-1 como P n\~ao um, sabemos que tal job come\c{c}ar\'a necessariamente
ap\'os P1. Ou seja, se Fi* for posicionado em outro lugar que n\~ao P1 por O, o algoritmo A termina em menor tempo. Por
outro lado, se Fi* \'e posicionado em P1 por O, como em A, temos que os dois seguem o mesmo valor \'otimo T. Assim
o algoritmo A mant\'em a propriedade de \"stays ahead\"(nota de rodape) de algoritmos gulosos.

\it Passo Indutivo: Aqui, considera-se que as itera\c{c}\~oes k =< n s\~ao v\'alidas.

A partir da hip\'otese indutiva podemos dizer que:

\begin{equation}\label{Inducao}
  \begin{split}
    T = Pk+1 + Fi-k* < Pk+j + Fi-k* = T` , sendo j > 1.
      \end{split}
\end{equation}

Isso \'e v\'alido pois Pn+j necessariamente come\c{c}a ap\'os Pn+1 o que faz do tempo em O ser maior do que em A. Se j = 1,
ent\~ao o algoritmo O possui tempo igual ao tempo de A, o que garante a propriedade de \it{stays ahead}.
Dessa forma, pode-se concluir que nosso algoritmo \'e \'otimo.


\end{document}
